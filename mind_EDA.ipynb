{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "def load_data():\n",
    "    # Read news and behaviors data\n",
    "    col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "    news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "    \n",
    "    col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "    behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "    behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)\n",
    "    \n",
    "    return news_df, behaviors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read news and behaviors data\n",
    "col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "# news_df = news_df.sample(frac=0.1, random_state=42)\n",
    "# Read behaviors data\n",
    "col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_impressions(behaviors_df, news_df):\n",
    "    \"\"\"Convert behaviors data into user-news interaction pairs\"\"\"\n",
    "    interactions = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        user_id = row['UserID']\n",
    "        history = row['History'].split() if pd.notna(row['History']) else []\n",
    "        \n",
    "        # Process each impression\n",
    "        for impression in row['Impressions'].split():\n",
    "            news_id, click = impression.split('-')\n",
    "            \n",
    "            # Only include if news exists in news_df\n",
    "            if news_id in news_df['NewsId'].values:\n",
    "                interactions.append({\n",
    "                    'user_id': user_id,\n",
    "                    'news_id': news_id,\n",
    "                    'click': int(click),\n",
    "                    'history_len': len(history),\n",
    "                    'time': row['Time']\n",
    "                })\n",
    "\n",
    "    # Convert interactions list to DataFrame\n",
    "    interactions_df = pd.DataFrame(interactions)\n",
    "    \n",
    "    # Separate clicks and no-clicks\n",
    "    clicks = interactions_df[interactions_df['click'] == 1]\n",
    "    no_clicks = interactions_df[interactions_df['click'] == 0]\n",
    "    \n",
    "    # Downsample no_clicks to match clicks size\n",
    "    no_clicks_downsampled = no_clicks.sample(n=len(clicks), random_state=42)\n",
    "    \n",
    "    # Combine back\n",
    "    balanced_df = pd.concat([clicks, no_clicks_downsampled])\n",
    "    \n",
    "    print(f\"Original size: {len(interactions_df)}, Balanced size: {len(balanced_df)}\")\n",
    "    print(\"Class distribution after balancing:\")\n",
    "    print(balanced_df['click'].value_counts())\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "def extract_time_features(time_str):\n",
    "    \"\"\"Extract time-based features from timestamp\"\"\"\n",
    "    time = datetime.strptime(time_str, '%m/%d/%Y %I:%M:%S %p')\n",
    "    return {\n",
    "        'hour': time.hour,\n",
    "        'day_of_week': time.weekday(),\n",
    "        'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "    }\n",
    "\n",
    "def prepare_features(interactions_df, news_df):\n",
    "    \"\"\"Prepare features for training\"\"\"\n",
    "    # Encode categorical features\n",
    "    # le_category = LabelEncoder()\n",
    "    # le_subcategory = LabelEncoder()\n",
    "    \n",
    "    # news_df['category_encoded'] = le_category.fit_transform(news_df['Category'])\n",
    "    # news_df['subcategory_encoded'] = le_subcategory.fit_transform(news_df['SubCat'])\n",
    "\n",
    "    # One-hot encode category and subcategory\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "\n",
    "    # Concatenate one-hot columns to news_df\n",
    "    news_df = pd.concat([news_df, category_ohe, subcategory_ohe], axis=1)\n",
    "\n",
    "    # Merge only necessary columns (include one-hot columns)\n",
    "    merged_news_cols = ['NewsId'] + list(category_ohe.columns) + list(subcategory_ohe.columns)\n",
    "\n",
    "    # Merge news features with interactions\n",
    "    features_df = interactions_df.merge(\n",
    "        news_df[merged_news_cols],\n",
    "        left_on='news_id',\n",
    "        right_on='NewsId'\n",
    "    )\n",
    "    \n",
    "    # Add time features\n",
    "    time_features = features_df['time'].apply(extract_time_features).apply(pd.Series)\n",
    "    features_df = pd.concat([features_df, time_features], axis=1)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = process_impressions(behaviors_df, news_df)\n",
    "interactions_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = prepare_features(interactions_df, news_df)\n",
    "features_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify one-hot encoded category/subcategory columns\n",
    "one_hot_cols = [col for col in features_df.columns if col.startswith('cat_') or col.startswith('subcat_')]\n",
    "\n",
    "# Identify history embedding columns if included previously\n",
    "history_emb_cols = [col for col in features_df.columns if col.startswith('hist_emb_')]\n",
    "\n",
    "# Core context features\n",
    "base_context_cols = ['history_len', 'hour', 'day_of_week', 'is_weekend']\n",
    "\n",
    "# Final feature set\n",
    "X = features_df[base_context_cols + one_hot_cols + history_emb_cols]\n",
    "y = features_df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features_df[[\n",
    "#         'history_len',\n",
    "#         'category_encoded',\n",
    "#         'subcategory_encoded',\n",
    "#         'hour',\n",
    "#         'day_of_week',\n",
    "#         'is_weekend'\n",
    "#     ]]\n",
    "# y = features_df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_losses = -log_loss(y_train, lr_model.predict_proba(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "    \n",
    "results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1': f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "print(\"LR Model Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read news and behaviors data\n",
    "col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "# news_df = news_df.sample(frac=0.1, random_state=42)\n",
    "# Read behaviors data\n",
    "col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_impressions_for_bandit(behaviors_df, news_df):\n",
    "    \"\"\"Convert behaviors data into bandit format with contexts and actions\"\"\"\n",
    "    \n",
    "    # One-hot encode news categories and subcategories\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "    \n",
    "    # Combine news features\n",
    "    news_features = pd.concat([\n",
    "        news_df[['NewsId']],\n",
    "        category_ohe,\n",
    "        subcategory_ohe\n",
    "    ], axis=1).set_index('NewsId')\n",
    "    \n",
    "    bandit_data = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        # Extract time features\n",
    "        time = datetime.strptime(row['Time'], '%m/%d/%Y %I:%M:%S %p')\n",
    "        context = {\n",
    "            'history_len': len(row['History'].split()) if pd.notna(row['History']) else 0,\n",
    "            'hour': time.hour,\n",
    "            'day_of_week': time.weekday(),\n",
    "            'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "        }\n",
    "        \n",
    "        # Process impressions\n",
    "        impressions = row['Impressions'].split()\n",
    "        slate = []\n",
    "        rewards = []\n",
    "        \n",
    "        for imp in impressions:\n",
    "            news_id, click = imp.split('-')\n",
    "            if news_id in news_features.index:  # Only include if news exists\n",
    "                slate.append(news_id)\n",
    "                rewards.append(int(click))\n",
    "        \n",
    "        if slate:  # Only include if there are valid articles\n",
    "            bandit_data.append({\n",
    "                'user_id': row['UserID'],\n",
    "                'context': context,\n",
    "                'slate': slate,\n",
    "                'rewards': rewards,\n",
    "                'news_features': news_features.loc[slate].to_dict('records')\n",
    "            })\n",
    "    \n",
    "    return bandit_data, news_features\n",
    "\n",
    "# Process data\n",
    "bandit_data, news_features = process_impressions_for_bandit(behaviors_df, news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_bandit(context, news_feat):\n",
    "    \"\"\"\n",
    "    Prepare features for LinUCB - combines context and pre-encoded news features\n",
    "    \n",
    "    Args:\n",
    "        context: dictionary with context features (history_len, hour, day_of_week, is_weekend)\n",
    "        news_feat: dictionary with pre-encoded news features from bandit data\n",
    "    \"\"\"\n",
    "    # Context features\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    # News features are already one-hot encoded in the bandit format\n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'], dtype=float)\n",
    "    \n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "# Create and fit the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare a sample of all possible feature vectors to fit the scaler\n",
    "all_feature_vectors = []\n",
    "for interaction in bandit_data:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        features = prepare_features_for_bandit(context, news_feat)\n",
    "        all_feature_vectors.append(features)\n",
    "\n",
    "# Fit the scaler on all possible feature combinations\n",
    "all_feature_vectors = np.array(all_feature_vectors)\n",
    "scaler.fit(all_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a scaler for the combined feature space\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare a sample of all possible feature vectors to fit the scaler\n",
    "all_feature_vectors = []\n",
    "for interaction in bandit_data:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        # Combine context and news features\n",
    "        features = prepare_features_for_bandit(context, news_feat)\n",
    "        all_feature_vectors.append(features)\n",
    "\n",
    "# Fit the scaler on all possible feature combinations\n",
    "all_feature_vectors = np.array(all_feature_vectors)\n",
    "scaler.fit(all_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinUCB:\n",
    "    def __init__(self, d, alpha=1.0):\n",
    "        \"\"\"\n",
    "        d: dimension of feature vectors\n",
    "        alpha: exploration parameter\n",
    "        \"\"\"\n",
    "        self.d = d\n",
    "        self.alpha = alpha\n",
    "        self.A = np.identity(d)\n",
    "        self.b = np.zeros(d)\n",
    "        self.theta = np.zeros(d)\n",
    "\n",
    "        # tracking metrics\n",
    "        self.total_regret = 0\n",
    "        self.cumulative_regret = []\n",
    "        \n",
    "    def get_action(self, context_features, actions_features_scaled):\n",
    "        \"\"\"\n",
    "        Select action using LinUCB\n",
    "        actions_features_scaled: list of pre-scaled feature vectors\n",
    "        \"\"\"\n",
    "        A_inv = np.linalg.inv(self.A)\n",
    "        self.theta = A_inv.dot(self.b)\n",
    "        \n",
    "        # Compute UCB for each action\n",
    "        ucb_scores = []\n",
    "        \n",
    "        for x in actions_features_scaled:\n",
    "            # Compute UCB score\n",
    "            mu = x.dot(self.theta)\n",
    "            sigma = np.sqrt(x.dot(A_inv).dot(x))\n",
    "            ucb = mu + self.alpha * sigma\n",
    "            \n",
    "            ucb_scores.append(float(ucb))\n",
    "            \n",
    "        return np.argmax(ucb_scores)\n",
    "    \n",
    "    def update(self, features_scaled, reward, optimal_reward):\n",
    "        \"\"\"Update model with observed reward\"\"\"\n",
    "        self.A += np.outer(features_scaled, features_scaled)\n",
    "        self.b += features_scaled * reward\n",
    "\n",
    "         # Update regret\n",
    "        regret = optimal_reward - reward\n",
    "        self.total_regret += regret\n",
    "        self.cumulative_regret.append(self.total_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(context, news_feat):\n",
    "    \"\"\"Combine context and news features into a single vector\"\"\"\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    # Convert news features dict to array, excluding NewsId\n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'])\n",
    "    \n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "def evaluate_linucb(model, eval_data):\n",
    "    \"\"\"Evaluate LinUCB on test data\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for interaction in eval_data:\n",
    "        context = interaction['context']\n",
    "        slate = interaction['slate']\n",
    "        rewards = interaction['rewards']\n",
    "        news_features = interaction['news_features']\n",
    "        \n",
    "        # Prepare features for each article in slate\n",
    "        action_features = [\n",
    "            prepare_features(context, news_feat) \n",
    "            for news_feat in news_features\n",
    "        ]\n",
    "        \n",
    "        # Get model prediction\n",
    "        pred_idx = model.get_action(\n",
    "            list(context.values()),\n",
    "            action_features\n",
    "        )\n",
    "        \n",
    "        # Check if prediction matches clicked article\n",
    "        if rewards[pred_idx] == 1:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_linucb_scaled(model, eval_data, scaler):\n",
    "    \"\"\"Evaluate LinUCB on test data with scaled features\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for interaction in eval_data:\n",
    "        context = interaction['context']\n",
    "        rewards = interaction['rewards']\n",
    "        \n",
    "        # Prepare and scale features for each article\n",
    "        action_features_scaled = []\n",
    "        for news_feat in interaction['news_features']:\n",
    "            features = prepare_features(context, news_feat)\n",
    "            features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "            action_features_scaled.append(features_scaled)\n",
    "        \n",
    "        # Get model prediction\n",
    "        pred_idx = model.get_action(\n",
    "            list(context.values()),\n",
    "            action_features_scaled\n",
    "        )\n",
    "        \n",
    "        # Check if prediction matches clicked article\n",
    "        if rewards[pred_idx] == 1:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "train_size = int(0.8 * len(bandit_data))\n",
    "train_data = bandit_data[:train_size]\n",
    "test_data = bandit_data[train_size:]\n",
    "\n",
    "# Initialize LinUCB\n",
    "d = 4 + len(news_features.columns)  # 4 context features + one-hot features\n",
    "bandit_model = LinUCB(d=d, alpha=1.0)\n",
    "\n",
    "# Train the model with scaled features\n",
    "for interaction in train_data:\n",
    "    context = interaction['context']\n",
    "    rewards = interaction['rewards']\n",
    "    \n",
    "    # Prepare and scale features for each article\n",
    "    action_features_scaled = []\n",
    "    for news_feat in interaction['news_features']:\n",
    "        # Combine context and news features\n",
    "        features = prepare_features(context, news_feat)\n",
    "        # Scale features\n",
    "        features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "        action_features_scaled.append(features_scaled)\n",
    "    \n",
    "    # Get model prediction\n",
    "    chosen_idx = bandit_model.get_action(\n",
    "        list(context.values()),\n",
    "        action_features_scaled\n",
    "    )\n",
    "    \n",
    "    optimal_reward = max(rewards)\n",
    "    # Update model with scaled features\n",
    "    bandit_model.update(\n",
    "        action_features_scaled[chosen_idx],\n",
    "        rewards[chosen_idx],\n",
    "        optimal_reward\n",
    "    )\n",
    "\n",
    "# Evaluate model\n",
    "test_accuracy = evaluate_linucb_scaled(bandit_model, test_data, scaler)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print random baseline\n",
    "avg_slate_size = np.mean([len(interaction['slate']) for interaction in bandit_data])\n",
    "random_baseline = 1/avg_slate_size\n",
    "print(f\"Random baseline (1/avg_slate_size): {random_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Single output for Q-value\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        \n",
    "    def push(self, state, action, reward, next_state):\n",
    "        self.buffer.append((state, action, reward, next_state))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.state_dim = state_dim\n",
    "        \n",
    "        # Networks\n",
    "        self.policy_net = DQNetwork(state_dim).to(device)\n",
    "        self.target_net = DQNetwork(state_dim).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        # Training parameters\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters())\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(10000)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.target_update = 10\n",
    "        self.steps = 0\n",
    "        \n",
    "    def select_action(self, state_features_list):\n",
    "        \"\"\"\n",
    "        Select action using epsilon-greedy policy\n",
    "        state_features_list: list of feature vectors for each article in slate\n",
    "        \"\"\"\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randrange(len(state_features_list))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            q_values = []\n",
    "            for features in state_features_list:\n",
    "                state = torch.FloatTensor(features).to(self.device)\n",
    "                q_value = self.policy_net(state)\n",
    "                q_values.append(q_value.item())\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    def update(self, batch_size):\n",
    "        if len(self.replay_buffer) < batch_size:\n",
    "            return\n",
    "        \n",
    "        # Sample batch\n",
    "        transitions = self.replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states = zip(*transitions)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        \n",
    "        # Compute Q(s_t, a)\n",
    "        current_q_values = self.policy_net(states)\n",
    "        \n",
    "        # Compute V(s_{t+1}) for all next states\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_net(next_states)\n",
    "            \n",
    "        # Compute expected Q values\n",
    "        expected_q_values = rewards + (self.gamma * next_q_values)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(current_q_values, expected_q_values)\n",
    "        \n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Update target network\n",
    "        self.steps += 1\n",
    "        if self.steps % self.target_update == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "            \n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "        \n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_dqn(behaviors_df, news_df):\n",
    "    \"\"\"Process data into format suitable for DQN training\"\"\"\n",
    "    # One-hot encode categories\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "    \n",
    "    # Combine news features\n",
    "    news_features = pd.concat([\n",
    "        news_df[['NewsId']],\n",
    "        category_ohe,\n",
    "        subcategory_ohe\n",
    "    ], axis=1).set_index('NewsId')\n",
    "    \n",
    "    interactions = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        # Extract time features\n",
    "        time = datetime.strptime(row['Time'], '%m/%d/%Y %I:%M:%S %p')\n",
    "        context = {\n",
    "            'history_len': len(row['History'].split()) if pd.notna(row['History']) else 0,\n",
    "            'hour': time.hour,\n",
    "            'day_of_week': time.weekday(),\n",
    "            'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "        }\n",
    "        \n",
    "        # Process impressions\n",
    "        impressions = row['Impressions'].split()\n",
    "        slate = []\n",
    "        rewards = []\n",
    "        \n",
    "        for imp in impressions:\n",
    "            news_id, click = imp.split('-')\n",
    "            if news_id in news_features.index:\n",
    "                slate.append(news_id)\n",
    "                rewards.append(int(click))\n",
    "        \n",
    "        if slate:\n",
    "            interactions.append({\n",
    "                'context': context,\n",
    "                'slate': slate,\n",
    "                'rewards': rewards,\n",
    "                'news_features': news_features.loc[slate].to_dict('records')\n",
    "            })\n",
    "    \n",
    "    return interactions, news_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_state_features(context, news_feat):\n",
    "    \"\"\"Combine context and news features into state representation\"\"\"\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'])\n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "def train_dqn(agent, train_data, scaler, num_epochs=5):\n",
    "    \"\"\"Train DQN agent\"\"\"\n",
    "    training_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for interaction in train_data:\n",
    "            context = interaction['context']\n",
    "            rewards = interaction['rewards']\n",
    "            \n",
    "            # Prepare state features for each article\n",
    "            state_features = []\n",
    "            for news_feat in interaction['news_features']:\n",
    "                features = prepare_state_features(context, news_feat)\n",
    "                features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "                state_features.append(features_scaled)\n",
    "            \n",
    "            # Select action\n",
    "            action = agent.select_action(state_features)\n",
    "            \n",
    "            # Get reward and update metrics\n",
    "            reward = rewards[action]\n",
    "            if reward == 1:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "            \n",
    "            # Store transition in replay buffer\n",
    "            state = state_features[action]\n",
    "            next_state = state  # Terminal state, so same as current\n",
    "            agent.replay_buffer.push(state, action, reward, next_state)\n",
    "            \n",
    "            # Update network\n",
    "            if len(agent.replay_buffer) >= agent.batch_size:\n",
    "                loss = agent.update(agent.batch_size)\n",
    "                if loss is not None:\n",
    "                    epoch_losses.append(loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        epoch_loss = np.mean(epoch_losses) if epoch_losses else 0\n",
    "        \n",
    "        accuracies.append(epoch_accuracy)\n",
    "        training_losses.append(epoch_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Accuracy: {epoch_accuracy:.4f}\")\n",
    "        print(f\"Average Loss: {epoch_loss:.4f}\")\n",
    "        print(f\"Epsilon: {agent.epsilon:.4f}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return training_losses, accuracies\n",
    "\n",
    "def evaluate_dqn(agent, eval_data, scaler):\n",
    "    \"\"\"Evaluate DQN agent\"\"\"\n",
    "    agent.policy_net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for interaction in eval_data:\n",
    "            context = interaction['context']\n",
    "            rewards = interaction['rewards']\n",
    "            \n",
    "            # Prepare state features\n",
    "            state_features = []\n",
    "            for news_feat in interaction['news_features']:\n",
    "                features = prepare_state_features(context, news_feat)\n",
    "                features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "                state_features.append(features_scaled)\n",
    "            \n",
    "            # Get model prediction (no epsilon-greedy during evaluation)\n",
    "            q_values = []\n",
    "            for features in state_features:\n",
    "                state = torch.FloatTensor(features).to(agent.device)\n",
    "                q_value = agent.policy_net(state)\n",
    "                q_values.append(q_value.item())\n",
    "            \n",
    "            pred_idx = np.argmax(q_values)\n",
    "            \n",
    "            if rewards[pred_idx] == 1:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    agent.policy_net.train()\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "news_df, behaviors_df = load_data()\n",
    "interactions, news_features = process_data_for_dqn(behaviors_df, news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature scaler\n",
    "all_features = []\n",
    "for interaction in interactions:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        features = prepare_state_features(context, news_feat)\n",
    "        all_features.append(features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(0.8 * len(interactions))\n",
    "train_data = interactions[:train_size]\n",
    "test_data = interactions[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DQN agent\n",
    "state_dim = len(all_features[0])  # 4 context features + one-hot features\n",
    "agent = DQNAgent(state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "training_losses, accuracies = train_dqn(agent, train_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_accuracy = evaluate_dqn(agent, test_data, scaler)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate random baseline\n",
    "avg_slate_size = np.mean([len(interaction['slate']) for interaction in interactions])\n",
    "random_baseline = 1/avg_slate_size\n",
    "print(f\"Random baseline (1/avg_slate_size): {random_baseline:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
