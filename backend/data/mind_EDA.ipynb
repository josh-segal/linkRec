{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "def load_data():\n",
    "    # Read news and behaviors data\n",
    "    col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "    news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "    \n",
    "    col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "    behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "    behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)\n",
    "    \n",
    "    return news_df, behaviors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read news and behaviors data\n",
    "col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "# news_df = news_df.sample(frac=0.1, random_state=42)\n",
    "# Read behaviors data\n",
    "col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "# behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51282, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(news_df['Category'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "print(news_df['SubCat'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(behaviors_df['UserID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "news             15774\n",
      "sports           14510\n",
      "finance           3107\n",
      "foodanddrink      2551\n",
      "lifestyle         2479\n",
      "travel            2350\n",
      "video             2068\n",
      "weather           2048\n",
      "health            1885\n",
      "autos             1639\n",
      "tv                 889\n",
      "music              769\n",
      "movies             606\n",
      "entertainment      587\n",
      "kids                17\n",
      "middleeast           2\n",
      "northamerica         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_counts = news_df['Category'].value_counts()\n",
    "subcat_counts = news_df['SubCat'].value_counts()\n",
    "print(cat_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsus: 6,564 articles\n",
      "football_nfl: 5,420 articles\n",
      "newspolitics: 2,826 articles\n",
      "newscrime: 2,254 articles\n",
      "weathertopstories: 2,047 articles\n",
      "newsworld: 1,720 articles\n",
      "football_ncaa: 1,665 articles\n",
      "baseball_mlb: 1,661 articles\n",
      "basketball_nba: 1,555 articles\n",
      "newsscienceandtechnology: 1,210 articles\n",
      "news: 1,185 articles\n",
      "newstrends: 1,176 articles\n",
      "more_sports: 1,065 articles\n",
      "travelarticle: 1,042 articles\n",
      "travelnews: 902 articles\n",
      "lifestylebuzz: 894 articles\n",
      "autosnews: 837 articles\n",
      "basketball_ncaa: 774 articles\n",
      "financenews: 697 articles\n",
      "finance-real-estate: 584 articles\n",
      "finance-companies: 567 articles\n",
      "icehockey_nhl: 531 articles\n",
      "medical: 479 articles\n",
      "recipes: 463 articles\n",
      "health-news: 459 articles\n",
      "golf: 446 articles\n",
      "mma: 437 articles\n",
      "musicnews: 414 articles\n",
      "markets: 410 articles\n",
      "newsoffbeat: 405 articles\n",
      "tvnews: 377 articles\n",
      "tv-celebrity: 356 articles\n",
      "wellness: 340 articles\n",
      "newsopinion: 315 articles\n",
      "racing: 299 articles\n",
      "foodnews: 271 articles\n",
      "animals: 259 articles\n",
      "tipsandtricks: 251 articles\n",
      "traveltripideas: 243 articles\n",
      "lifestyleroyals: 239 articles\n",
      "movienews: 231 articles\n",
      "autosenthusiasts: 231 articles\n",
      "nutrition: 222 articles\n",
      "viral: 217 articles\n",
      "movies-celebrity: 213 articles\n",
      "music-celebrity: 210 articles\n",
      "lifestylehomeandgarden: 178 articles\n",
      "newsgoodnews: 176 articles\n",
      "restaurantsandnews: 170 articles\n",
      "football_nfl_videos: 161 articles\n",
      "soccer: 156 articles\n",
      "lifestylefamily: 147 articles\n",
      "celebrity: 145 articles\n",
      "voices: 143 articles\n",
      "science: 135 articles\n",
      "entertainment-celebrity: 129 articles\n",
      "autosmotorcycles: 128 articles\n",
      "weightloss: 127 articles\n",
      "lifestyle: 122 articles\n",
      "personalfinance: 120 articles\n",
      "autosclassics: 119 articles\n",
      "finance-career-education: 118 articles\n",
      "finance-top-stocks: 117 articles\n",
      "elections-2020-us: 116 articles\n",
      "gaming: 115 articles\n",
      "tennis: 111 articles\n",
      "entertainment-books: 110 articles\n",
      "fitness: 107 articles\n",
      "shop-holidays: 107 articles\n",
      "lifestyledidyouknow: 103 articles\n",
      "popculture: 98 articles\n",
      "video: 94 articles\n",
      "videos: 87 articles\n",
      "finance-video: 81 articles\n",
      "tv-gallery: 78 articles\n",
      "lifestylepets: 77 articles\n",
      "movievideo: 77 articles\n",
      "traveltips: 76 articles\n",
      "finance-retirement: 76 articles\n",
      "finance-saving-investing: 71 articles\n",
      "autossuvs: 68 articles\n",
      "lifestylepetsanimals: 67 articles\n",
      "finance-savemoney: 65 articles\n",
      "movies-gallery: 64 articles\n",
      "beverages: 63 articles\n",
      "lifestylesmartliving: 61 articles\n",
      "lifestylecelebstyle: 59 articles\n",
      "autossports: 58 articles\n",
      "peopleandplaces: 54 articles\n",
      "newsbusiness: 48 articles\n",
      "music-gallery: 48 articles\n",
      "quickandeasy: 44 articles\n",
      "factcheck: 40 articles\n",
      "tvvideos: 39 articles\n",
      "soccer_mls: 37 articles\n",
      "cma-awards: 37 articles\n",
      "finance-taxes: 37 articles\n",
      "lifestylerelationships: 36 articles\n",
      "autostrucks: 36 articles\n",
      "baseball_mlb_videos: 36 articles\n",
      "football_ncaa_videos: 36 articles\n",
      "healthnews: 36 articles\n",
      "lifestylehoroscope: 34 articles\n",
      "outdoors: 34 articles\n",
      "finance-small-business: 32 articles\n",
      "autosbuying: 32 articles\n",
      "shop-all: 32 articles\n",
      "lifestyleparenting: 30 articles\n",
      "lifestylebeauty: 30 articles\n",
      "lifestylecareer: 30 articles\n",
      "lifestylemindandsoul: 29 articles\n",
      "lifestylefamilyandrelationships: 28 articles\n",
      "causes: 27 articles\n",
      "awards: 27 articles\n",
      "autosownership: 26 articles\n",
      "music-awards: 26 articles\n",
      "advice: 25 articles\n",
      "humor: 25 articles\n",
      "soccer_epl: 25 articles\n",
      "lifestylecleaningandorganizing: 23 articles\n",
      "newsphotos: 22 articles\n",
      "autosluxury: 20 articles\n",
      "finance-technology: 20 articles\n",
      "autossema: 19 articles\n",
      "finance-career: 18 articles\n",
      "newsfactcheck: 17 articles\n",
      "shop-apparel: 17 articles\n",
      "musicvideos: 17 articles\n",
      "tv-recaps: 16 articles\n",
      "finance-credit: 16 articles\n",
      "lifestylevideo: 16 articles\n",
      "autosresearchguides: 16 articles\n",
      "finance-insurance: 15 articles\n",
      "boxing: 15 articles\n",
      "lifestylefashion: 15 articles\n",
      "lifestylelovesex: 15 articles\n",
      "newsscience: 15 articles\n",
      "autosresearch: 15 articles\n",
      "basketball_ncaa_videos: 14 articles\n",
      "finance-healthcare: 14 articles\n",
      "lifestyle-news-feature: 14 articles\n",
      "wines: 13 articles\n",
      "lifestylediy: 13 articles\n",
      "finance-billstopay: 12 articles\n",
      "awardstyle: 12 articles\n",
      "movies-awards: 12 articles\n",
      "ads-lung-health: 11 articles\n",
      "newsweather: 11 articles\n",
      "finance-education: 11 articles\n",
      "lifestyleweddings: 11 articles\n",
      "travel-points-rewards: 10 articles\n",
      "retirement: 10 articles\n",
      "mentalhealth: 9 articles\n",
      "pregnancyparenting: 9 articles\n",
      "basketball_nba_videos: 9 articles\n",
      "boxing-mma: 8 articles\n",
      "lifestyledecor: 8 articles\n",
      "newselection2020: 8 articles\n",
      "autosvideonew: 7 articles\n",
      "ads-latingrammys: 7 articles\n",
      "ustravel: 6 articles\n",
      "weight-loss: 6 articles\n",
      "autoshybrids: 6 articles\n",
      "autostokyo: 6 articles\n",
      "movies-oscars: 5 articles\n",
      "causes-animals: 5 articles\n",
      "internationaltravel: 5 articles\n",
      "newsworldpolitics: 5 articles\n",
      "causes-green-living: 5 articles\n",
      "lifestyleshopping: 5 articles\n",
      "wonder: 5 articles\n",
      "tunedin: 5 articles\n",
      "people-places: 5 articles\n",
      "tv-golden-globes: 4 articles\n",
      "travel-adventure-travel: 4 articles\n",
      "basketball_wnba: 4 articles\n",
      "sports_news: 4 articles\n",
      "reviews: 4 articles\n",
      "fun: 4 articles\n",
      "music-reviews: 4 articles\n",
      "music-grammys: 4 articles\n",
      "causes-food-insecurity: 4 articles\n",
      "finance-mutual-funds: 4 articles\n",
      "holidays: 4 articles\n",
      "cooking: 3 articles\n",
      "downtime: 3 articles\n",
      "autospassenger: 3 articles\n",
      "foodrecipes: 3 articles\n",
      "autosvideos: 3 articles\n",
      "autosreview: 3 articles\n",
      "shop-home-goods: 3 articles\n",
      "indepth: 2 articles\n",
      "photos: 2 articles\n",
      "autoscartech: 2 articles\n",
      "travel-videos: 2 articles\n",
      "middleeast-top-stories: 2 articles\n",
      "technologyinvesting: 2 articles\n",
      "tv-reviews: 2 articles\n",
      "healthagingwell: 2 articles\n",
      "career-news: 2 articles\n",
      "shop-books-movies-tv: 2 articles\n",
      "yearinoffbeatgoodnews: 2 articles\n",
      "topnews: 2 articles\n",
      "seasonal: 2 articles\n",
      "cocktails: 2 articles\n",
      "causes-environment: 2 articles\n",
      "sports: 2 articles\n",
      "healthyliving: 1 articles\n",
      "cardio: 1 articles\n",
      "lifestylewhatshot: 1 articles\n",
      "causes-military-appreciation: 1 articles\n",
      "weatherfullscreenmaps: 1 articles\n",
      "finance-auto-insurance: 1 articles\n",
      "causes-disaster-relief: 1 articles\n",
      "autoslosangeles: 1 articles\n",
      "entertainmenttv: 1 articles\n",
      "lifestylestyle: 1 articles\n",
      "autosmidsize: 1 articles\n",
      "northamerica-video: 1 articles\n",
      "health-cancer: 1 articles\n",
      "strength: 1 articles\n",
      "entertainmentmusic: 1 articles\n",
      "finance-startinvesting: 1 articles\n",
      "spendingandborrowing: 1 articles\n",
      "tennis_intl: 1 articles\n",
      "foodanddrink: 1 articles\n",
      "tv-golden-globes-video: 1 articles\n",
      "soccer_bund: 1 articles\n",
      "comedy: 1 articles\n",
      "traveltrivia: 1 articles\n",
      "watch: 1 articles\n",
      "cookingschool: 1 articles\n",
      "foodtips: 1 articles\n",
      "newsother: 1 articles\n",
      "hollywood: 1 articles\n",
      "finance-home-loans: 1 articles\n",
      "games: 1 articles\n",
      "relationships: 1 articles\n",
      "celebritynews: 1 articles\n",
      "causes-poverty: 1 articles\n",
      "lifestyle-wedding: 1 articles\n",
      "autoscompact: 1 articles\n",
      "finance-insidetheticker: 1 articles\n",
      "olympics-videos: 1 articles\n",
      "golfvideos: 1 articles\n",
      "autosvans: 1 articles\n",
      "newstvmedia: 1 articles\n",
      "mmaufc: 1 articles\n",
      "narendramodi_opinion: 1 articles\n",
      "lifestylemarriage: 1 articles\n",
      "finance-homesandpropertysection: 1 articles\n",
      "tv: 1 articles\n",
      "newsnational: 1 articles\n",
      "halloween: 1 articles\n",
      "empowering-the-planet: 1 articles\n",
      "company-news: 1 articles\n",
      "othersports: 1 articles\n",
      "newsrealestate: 1 articles\n",
      "lifestyleshoppinghomegarden: 1 articles\n",
      "newsvideo: 1 articles\n",
      "travel: 1 articles\n",
      "lifestylehoroscopefish: 1 articles\n",
      "baseball: 1 articles\n",
      "celebhub: 1 articles\n"
     ]
    }
   ],
   "source": [
    "for subcat, count in subcat_counts.items():\n",
    "    print(f\"{subcat}: {count:,} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156965, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_impressions(behaviors_df, news_df):\n",
    "    \"\"\"Convert behaviors data into user-news interaction pairs\"\"\"\n",
    "    interactions = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        user_id = row['UserID']\n",
    "        history = row['History'].split() if pd.notna(row['History']) else []\n",
    "        \n",
    "        # Process each impression\n",
    "        for impression in row['Impressions'].split():\n",
    "            news_id, click = impression.split('-')\n",
    "            \n",
    "            # Only include if news exists in news_df\n",
    "            if news_id in news_df['NewsId'].values:\n",
    "                interactions.append({\n",
    "                    'user_id': user_id,\n",
    "                    'news_id': news_id,\n",
    "                    'click': int(click),\n",
    "                    'history_len': len(history),\n",
    "                    'time': row['Time']\n",
    "                })\n",
    "\n",
    "    # Convert interactions list to DataFrame\n",
    "    interactions_df = pd.DataFrame(interactions)\n",
    "    \n",
    "    # Separate clicks and no-clicks\n",
    "    clicks = interactions_df[interactions_df['click'] == 1]\n",
    "    no_clicks = interactions_df[interactions_df['click'] == 0]\n",
    "    \n",
    "    # Downsample no_clicks to match clicks size\n",
    "    no_clicks_downsampled = no_clicks.sample(n=len(clicks), random_state=42)\n",
    "    \n",
    "    # Combine back\n",
    "    balanced_df = pd.concat([clicks, no_clicks_downsampled])\n",
    "    \n",
    "    print(f\"Original size: {len(interactions_df)}, Balanced size: {len(balanced_df)}\")\n",
    "    print(\"Class distribution after balancing:\")\n",
    "    print(balanced_df['click'].value_counts())\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "def extract_time_features(time_str):\n",
    "    \"\"\"Extract time-based features from timestamp\"\"\"\n",
    "    time = datetime.strptime(time_str, '%m/%d/%Y %I:%M:%S %p')\n",
    "    return {\n",
    "        'hour': time.hour,\n",
    "        'day_of_week': time.weekday(),\n",
    "        'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "    }\n",
    "\n",
    "def prepare_features(interactions_df, news_df):\n",
    "    \"\"\"Prepare features for training\"\"\"\n",
    "    # Encode categorical features\n",
    "    # le_category = LabelEncoder()\n",
    "    # le_subcategory = LabelEncoder()\n",
    "    \n",
    "    # news_df['category_encoded'] = le_category.fit_transform(news_df['Category'])\n",
    "    # news_df['subcategory_encoded'] = le_subcategory.fit_transform(news_df['SubCat'])\n",
    "\n",
    "    # One-hot encode category and subcategory\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "\n",
    "    # Concatenate one-hot columns to news_df\n",
    "    news_df = pd.concat([news_df, category_ohe, subcategory_ohe], axis=1)\n",
    "\n",
    "    # Merge only necessary columns (include one-hot columns)\n",
    "    merged_news_cols = ['NewsId'] + list(category_ohe.columns) + list(subcategory_ohe.columns)\n",
    "\n",
    "    # Merge news features with interactions\n",
    "    features_df = interactions_df.merge(\n",
    "        news_df[merged_news_cols],\n",
    "        left_on='news_id',\n",
    "        right_on='NewsId'\n",
    "    )\n",
    "    \n",
    "    # Add time features\n",
    "    time_features = features_df['time'].apply(extract_time_features).apply(pd.Series)\n",
    "    features_df = pd.concat([features_df, time_features], axis=1)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = process_impressions(behaviors_df, news_df)\n",
    "interactions_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = prepare_features(interactions_df, news_df)\n",
    "features_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify one-hot encoded category/subcategory columns\n",
    "one_hot_cols = [col for col in features_df.columns if col.startswith('cat_') or col.startswith('subcat_')]\n",
    "\n",
    "# Identify history embedding columns if included previously\n",
    "history_emb_cols = [col for col in features_df.columns if col.startswith('hist_emb_')]\n",
    "\n",
    "# Core context features\n",
    "base_context_cols = ['history_len', 'hour', 'day_of_week', 'is_weekend']\n",
    "\n",
    "# Final feature set\n",
    "X = features_df[base_context_cols + one_hot_cols + history_emb_cols]\n",
    "y = features_df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features_df[[\n",
    "#         'history_len',\n",
    "#         'category_encoded',\n",
    "#         'subcategory_encoded',\n",
    "#         'hour',\n",
    "#         'day_of_week',\n",
    "#         'is_weekend'\n",
    "#     ]]\n",
    "# y = features_df['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_losses = -log_loss(y_train, lr_model.predict_proba(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "    \n",
    "results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1': f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "print(\"LR Model Performance:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read news and behaviors data\n",
    "col_news = ['NewsId', 'Category', 'SubCat', 'Title', 'Abstract', 'url', 'TitleEnt', 'AbstractEnt']\n",
    "news_df = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_news)\n",
    "# news_df = news_df.sample(frac=0.1, random_state=42)\n",
    "# Read behaviors data\n",
    "col_behaviors = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "behaviors_df = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_behaviors)\n",
    "behaviors_df = behaviors_df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_impressions_for_bandit(behaviors_df, news_df):\n",
    "    \"\"\"Convert behaviors data into bandit format with contexts and actions\"\"\"\n",
    "    \n",
    "    # One-hot encode news categories and subcategories\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "    \n",
    "    # Combine news features\n",
    "    news_features = pd.concat([\n",
    "        news_df[['NewsId']],\n",
    "        category_ohe,\n",
    "        subcategory_ohe\n",
    "    ], axis=1).set_index('NewsId')\n",
    "    \n",
    "    bandit_data = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        # Extract time features\n",
    "        time = datetime.strptime(row['Time'], '%m/%d/%Y %I:%M:%S %p')\n",
    "        context = {\n",
    "            'history_len': len(row['History'].split()) if pd.notna(row['History']) else 0,\n",
    "            'hour': time.hour,\n",
    "            'day_of_week': time.weekday(),\n",
    "            'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "        }\n",
    "        \n",
    "        # Process impressions\n",
    "        impressions = row['Impressions'].split()\n",
    "        slate = []\n",
    "        rewards = []\n",
    "        \n",
    "        for imp in impressions:\n",
    "            news_id, click = imp.split('-')\n",
    "            if news_id in news_features.index:  # Only include if news exists\n",
    "                slate.append(news_id)\n",
    "                rewards.append(int(click))\n",
    "        \n",
    "        if slate:  # Only include if there are valid articles\n",
    "            bandit_data.append({\n",
    "                'user_id': row['UserID'],\n",
    "                'context': context,\n",
    "                'slate': slate,\n",
    "                'rewards': rewards,\n",
    "                'news_features': news_features.loc[slate].to_dict('records')\n",
    "            })\n",
    "    \n",
    "    return bandit_data, news_features\n",
    "\n",
    "# Process data\n",
    "bandit_data, news_features = process_impressions_for_bandit(behaviors_df, news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_bandit(context, news_feat):\n",
    "    \"\"\"\n",
    "    Prepare features for LinUCB - combines context and pre-encoded news features\n",
    "    \n",
    "    Args:\n",
    "        context: dictionary with context features (history_len, hour, day_of_week, is_weekend)\n",
    "        news_feat: dictionary with pre-encoded news features from bandit data\n",
    "    \"\"\"\n",
    "    # Context features\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    # News features are already one-hot encoded in the bandit format\n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'], dtype=float)\n",
    "    \n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "# Create and fit the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare a sample of all possible feature vectors to fit the scaler\n",
    "all_feature_vectors = []\n",
    "for interaction in bandit_data:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        features = prepare_features_for_bandit(context, news_feat)\n",
    "        all_feature_vectors.append(features)\n",
    "\n",
    "# Fit the scaler on all possible feature combinations\n",
    "all_feature_vectors = np.array(all_feature_vectors)\n",
    "scaler.fit(all_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a scaler for the combined feature space\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare a sample of all possible feature vectors to fit the scaler\n",
    "all_feature_vectors = []\n",
    "for interaction in bandit_data:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        # Combine context and news features\n",
    "        features = prepare_features_for_bandit(context, news_feat)\n",
    "        all_feature_vectors.append(features)\n",
    "\n",
    "# Fit the scaler on all possible feature combinations\n",
    "all_feature_vectors = np.array(all_feature_vectors)\n",
    "scaler.fit(all_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinUCB:\n",
    "    def __init__(self, d, alpha=1.0):\n",
    "        \"\"\"\n",
    "        d: dimension of feature vectors\n",
    "        alpha: exploration parameter\n",
    "        \"\"\"\n",
    "        self.d = d\n",
    "        self.alpha = alpha\n",
    "        self.A = np.identity(d)\n",
    "        self.b = np.zeros(d)\n",
    "        self.theta = np.zeros(d)\n",
    "\n",
    "        # tracking metrics\n",
    "        self.total_regret = 0\n",
    "        self.cumulative_regret = []\n",
    "        \n",
    "    def get_action(self, context_features, actions_features_scaled):\n",
    "        \"\"\"\n",
    "        Select action using LinUCB\n",
    "        actions_features_scaled: list of pre-scaled feature vectors\n",
    "        \"\"\"\n",
    "        A_inv = np.linalg.inv(self.A)\n",
    "        self.theta = A_inv.dot(self.b)\n",
    "        \n",
    "        # Compute UCB for each action\n",
    "        ucb_scores = []\n",
    "        \n",
    "        for x in actions_features_scaled:\n",
    "            # Compute UCB score\n",
    "            mu = x.dot(self.theta)\n",
    "            sigma = np.sqrt(x.dot(A_inv).dot(x))\n",
    "            ucb = mu + self.alpha * sigma\n",
    "            \n",
    "            ucb_scores.append(float(ucb))\n",
    "            \n",
    "        return np.argmax(ucb_scores)\n",
    "    \n",
    "    def update(self, features_scaled, reward, optimal_reward):\n",
    "        \"\"\"Update model with observed reward\"\"\"\n",
    "        self.A += np.outer(features_scaled, features_scaled)\n",
    "        self.b += features_scaled * reward\n",
    "\n",
    "         # Update regret\n",
    "        regret = optimal_reward - reward\n",
    "        self.total_regret += regret\n",
    "        self.cumulative_regret.append(self.total_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(context, news_feat):\n",
    "    \"\"\"Combine context and news features into a single vector\"\"\"\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    # Convert news features dict to array, excluding NewsId\n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'])\n",
    "    \n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "def evaluate_linucb(model, eval_data):\n",
    "    \"\"\"Evaluate LinUCB on test data\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for interaction in eval_data:\n",
    "        context = interaction['context']\n",
    "        slate = interaction['slate']\n",
    "        rewards = interaction['rewards']\n",
    "        news_features = interaction['news_features']\n",
    "        \n",
    "        # Prepare features for each article in slate\n",
    "        action_features = [\n",
    "            prepare_features(context, news_feat) \n",
    "            for news_feat in news_features\n",
    "        ]\n",
    "        \n",
    "        # Get model prediction\n",
    "        pred_idx = model.get_action(\n",
    "            list(context.values()),\n",
    "            action_features\n",
    "        )\n",
    "        \n",
    "        # Check if prediction matches clicked article\n",
    "        if rewards[pred_idx] == 1:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_linucb_scaled(model, eval_data, scaler):\n",
    "    \"\"\"Evaluate LinUCB on test data with scaled features\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for interaction in eval_data:\n",
    "        context = interaction['context']\n",
    "        rewards = interaction['rewards']\n",
    "        \n",
    "        # Prepare and scale features for each article\n",
    "        action_features_scaled = []\n",
    "        for news_feat in interaction['news_features']:\n",
    "            features = prepare_features(context, news_feat)\n",
    "            features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "            action_features_scaled.append(features_scaled)\n",
    "        \n",
    "        # Get model prediction\n",
    "        pred_idx = model.get_action(\n",
    "            list(context.values()),\n",
    "            action_features_scaled\n",
    "        )\n",
    "        \n",
    "        # Check if prediction matches clicked article\n",
    "        if rewards[pred_idx] == 1:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "train_size = int(0.8 * len(bandit_data))\n",
    "train_data = bandit_data[:train_size]\n",
    "test_data = bandit_data[train_size:]\n",
    "\n",
    "# Initialize LinUCB\n",
    "d = 4 + len(news_features.columns)  # 4 context features + one-hot features\n",
    "bandit_model = LinUCB(d=d, alpha=1.0)\n",
    "\n",
    "# Train the model with scaled features\n",
    "for interaction in train_data:\n",
    "    context = interaction['context']\n",
    "    rewards = interaction['rewards']\n",
    "    \n",
    "    # Prepare and scale features for each article\n",
    "    action_features_scaled = []\n",
    "    for news_feat in interaction['news_features']:\n",
    "        # Combine context and news features\n",
    "        features = prepare_features(context, news_feat)\n",
    "        # Scale features\n",
    "        features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "        action_features_scaled.append(features_scaled)\n",
    "    \n",
    "    # Get model prediction\n",
    "    chosen_idx = bandit_model.get_action(\n",
    "        list(context.values()),\n",
    "        action_features_scaled\n",
    "    )\n",
    "    \n",
    "    optimal_reward = max(rewards)\n",
    "    # Update model with scaled features\n",
    "    bandit_model.update(\n",
    "        action_features_scaled[chosen_idx],\n",
    "        rewards[chosen_idx],\n",
    "        optimal_reward\n",
    "    )\n",
    "\n",
    "# Evaluate model\n",
    "test_accuracy = evaluate_linucb_scaled(bandit_model, test_data, scaler)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print random baseline\n",
    "avg_slate_size = np.mean([len(interaction['slate']) for interaction in bandit_data])\n",
    "random_baseline = 1/avg_slate_size\n",
    "print(f\"Random baseline (1/avg_slate_size): {random_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Single output for Q-value\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        \n",
    "    def push(self, state, action, reward, next_state):\n",
    "        self.buffer.append((state, action, reward, next_state))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.state_dim = state_dim\n",
    "        \n",
    "        # Networks\n",
    "        self.policy_net = DQNetwork(state_dim).to(device)\n",
    "        self.target_net = DQNetwork(state_dim).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        # Training parameters\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters())\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(10000)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.target_update = 10\n",
    "        self.steps = 0\n",
    "        \n",
    "    def select_action(self, state_features_list):\n",
    "        \"\"\"\n",
    "        Select action using epsilon-greedy policy\n",
    "        state_features_list: list of feature vectors for each article in slate\n",
    "        \"\"\"\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randrange(len(state_features_list))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            q_values = []\n",
    "            for features in state_features_list:\n",
    "                state = torch.FloatTensor(features).to(self.device)\n",
    "                q_value = self.policy_net(state)\n",
    "                q_values.append(q_value.item())\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    def update(self, batch_size):\n",
    "        if len(self.replay_buffer) < batch_size:\n",
    "            return\n",
    "        \n",
    "        # Sample batch\n",
    "        transitions = self.replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states = zip(*transitions)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        \n",
    "        # Compute Q(s_t, a)\n",
    "        current_q_values = self.policy_net(states)\n",
    "        \n",
    "        # Compute V(s_{t+1}) for all next states\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_net(next_states)\n",
    "            \n",
    "        # Compute expected Q values\n",
    "        expected_q_values = rewards + (self.gamma * next_q_values)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(current_q_values, expected_q_values)\n",
    "        \n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Update target network\n",
    "        self.steps += 1\n",
    "        if self.steps % self.target_update == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "            \n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "        \n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_dqn(behaviors_df, news_df):\n",
    "    \"\"\"Process data into format suitable for DQN training\"\"\"\n",
    "    # One-hot encode categories\n",
    "    category_ohe = pd.get_dummies(news_df['Category'], prefix='cat')\n",
    "    subcategory_ohe = pd.get_dummies(news_df['SubCat'], prefix='subcat')\n",
    "    \n",
    "    # Combine news features\n",
    "    news_features = pd.concat([\n",
    "        news_df[['NewsId']],\n",
    "        category_ohe,\n",
    "        subcategory_ohe\n",
    "    ], axis=1).set_index('NewsId')\n",
    "    \n",
    "    interactions = []\n",
    "    \n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        # Extract time features\n",
    "        time = datetime.strptime(row['Time'], '%m/%d/%Y %I:%M:%S %p')\n",
    "        context = {\n",
    "            'history_len': len(row['History'].split()) if pd.notna(row['History']) else 0,\n",
    "            'hour': time.hour,\n",
    "            'day_of_week': time.weekday(),\n",
    "            'is_weekend': 1 if time.weekday() >= 5 else 0\n",
    "        }\n",
    "        \n",
    "        # Process impressions\n",
    "        impressions = row['Impressions'].split()\n",
    "        slate = []\n",
    "        rewards = []\n",
    "        \n",
    "        for imp in impressions:\n",
    "            news_id, click = imp.split('-')\n",
    "            if news_id in news_features.index:\n",
    "                slate.append(news_id)\n",
    "                rewards.append(int(click))\n",
    "        \n",
    "        if slate:\n",
    "            interactions.append({\n",
    "                'context': context,\n",
    "                'slate': slate,\n",
    "                'rewards': rewards,\n",
    "                'news_features': news_features.loc[slate].to_dict('records')\n",
    "            })\n",
    "    \n",
    "    return interactions, news_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_state_features(context, news_feat):\n",
    "    \"\"\"Combine context and news features into state representation\"\"\"\n",
    "    context_vec = np.array([\n",
    "        context['history_len'],\n",
    "        context['hour'],\n",
    "        context['day_of_week'],\n",
    "        context['is_weekend']\n",
    "    ])\n",
    "    \n",
    "    news_vec = np.array([v for k, v in news_feat.items() if k != 'NewsId'])\n",
    "    return np.concatenate([context_vec, news_vec])\n",
    "\n",
    "def train_dqn(agent, train_data, scaler, num_epochs=5):\n",
    "    \"\"\"Train DQN agent\"\"\"\n",
    "    training_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for interaction in train_data:\n",
    "            context = interaction['context']\n",
    "            rewards = interaction['rewards']\n",
    "            \n",
    "            # Prepare state features for each article\n",
    "            state_features = []\n",
    "            for news_feat in interaction['news_features']:\n",
    "                features = prepare_state_features(context, news_feat)\n",
    "                features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "                state_features.append(features_scaled)\n",
    "            \n",
    "            # Select action\n",
    "            action = agent.select_action(state_features)\n",
    "            \n",
    "            # Get reward and update metrics\n",
    "            reward = rewards[action]\n",
    "            if reward == 1:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "            \n",
    "            # Store transition in replay buffer\n",
    "            state = state_features[action]\n",
    "            next_state = state  # Terminal state, so same as current\n",
    "            agent.replay_buffer.push(state, action, reward, next_state)\n",
    "            \n",
    "            # Update network\n",
    "            if len(agent.replay_buffer) >= agent.batch_size:\n",
    "                loss = agent.update(agent.batch_size)\n",
    "                if loss is not None:\n",
    "                    epoch_losses.append(loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        epoch_loss = np.mean(epoch_losses) if epoch_losses else 0\n",
    "        \n",
    "        accuracies.append(epoch_accuracy)\n",
    "        training_losses.append(epoch_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Accuracy: {epoch_accuracy:.4f}\")\n",
    "        print(f\"Average Loss: {epoch_loss:.4f}\")\n",
    "        print(f\"Epsilon: {agent.epsilon:.4f}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return training_losses, accuracies\n",
    "\n",
    "def evaluate_dqn(agent, eval_data, scaler):\n",
    "    \"\"\"Evaluate DQN agent\"\"\"\n",
    "    agent.policy_net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for interaction in eval_data:\n",
    "            context = interaction['context']\n",
    "            rewards = interaction['rewards']\n",
    "            \n",
    "            # Prepare state features\n",
    "            state_features = []\n",
    "            for news_feat in interaction['news_features']:\n",
    "                features = prepare_state_features(context, news_feat)\n",
    "                features_scaled = scaler.transform(features.reshape(1, -1))[0]\n",
    "                state_features.append(features_scaled)\n",
    "            \n",
    "            # Get model prediction (no epsilon-greedy during evaluation)\n",
    "            q_values = []\n",
    "            for features in state_features:\n",
    "                state = torch.FloatTensor(features).to(agent.device)\n",
    "                q_value = agent.policy_net(state)\n",
    "                q_values.append(q_value.item())\n",
    "            \n",
    "            pred_idx = np.argmax(q_values)\n",
    "            \n",
    "            if rewards[pred_idx] == 1:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    agent.policy_net.train()\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "news_df, behaviors_df = load_data()\n",
    "interactions, news_features = process_data_for_dqn(behaviors_df, news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature scaler\n",
    "all_features = []\n",
    "for interaction in interactions:\n",
    "    context = interaction['context']\n",
    "    for news_feat in interaction['news_features']:\n",
    "        features = prepare_state_features(context, news_feat)\n",
    "        all_features.append(features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(0.8 * len(interactions))\n",
    "train_data = interactions[:train_size]\n",
    "test_data = interactions[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DQN agent\n",
    "state_dim = len(all_features[0])  # 4 context features + one-hot features\n",
    "agent = DQNAgent(state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "training_losses, accuracies = train_dqn(agent, train_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_accuracy = evaluate_dqn(agent, test_data, scaler)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate random baseline\n",
    "avg_slate_size = np.mean([len(interaction['slate']) for interaction in interactions])\n",
    "random_baseline = 1/avg_slate_size\n",
    "print(f\"Random baseline (1/avg_slate_size): {random_baseline:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
